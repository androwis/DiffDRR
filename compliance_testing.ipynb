{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80496bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from diffdrr import DRR, load_example_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d2f2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "volume, spacing = load_example_ct()\n",
    "\n",
    "params = torch.tensor([[250.0, 3.14, 0.0, 1.57, 150.0, 150.0, 150.0]])\n",
    "\n",
    "drr = DRR(\n",
    "    volume,\n",
    "    spacing,\n",
    "    height=100,\n",
    "    delx=8.0,\n",
    "    optimization_mode=True,\n",
    "    params=params\n",
    ").to(device=\"mps\", dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68bdca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "source, target = drr.detector.make_xrays(\n",
    "    drr.sdr,\n",
    "    drr.rotations,\n",
    "    drr.translations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b911d35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivek/Documents/MedicalVision/DiffDRR/diffdrr/projectors/siddon.py:52: UserWarning: The operator 'aten::nonzero' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1670525498485/work/aten/src/ATen/mps/MPSFallback.mm:11.)\n",
      "  alphas[~good_idxs] = torch.nan\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::sort.values_stable' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdrr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/DiffDRR/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/MedicalVision/DiffDRR/diffdrr/drr.py:137\u001b[0m, in \u001b[0;36mDRR.forward\u001b[0;34m(self, sdr, theta, phi, gamma, bx, by, bz)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot provide parameters in optimization mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m source, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector\u001b[38;5;241m.\u001b[39mmake_xrays(\n\u001b[1;32m    133\u001b[0m     sdr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msdr,\n\u001b[1;32m    134\u001b[0m     rotations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotations,\n\u001b[1;32m    135\u001b[0m     translations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtranslations,\n\u001b[1;32m    136\u001b[0m )\n\u001b[0;32m--> 137\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msiddon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraytrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreshape:\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetector\u001b[38;5;241m.\u001b[39mn_subsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/MedicalVision/DiffDRR/diffdrr/projectors/siddon.py:81\u001b[0m, in \u001b[0;36mSiddon.raytrace\u001b[0;34m(self, source, target)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraytrace\u001b[39m(\u001b[38;5;28mself\u001b[39m, source, target):\n\u001b[0;32m---> 81\u001b[0m     alphas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_alphas\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     alphamid \u001b[38;5;241m=\u001b[39m (alphas[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m alphas[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     83\u001b[0m     voxels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_voxel(alphamid, source, target)\n",
      "File \u001b[0;32m~/Documents/MedicalVision/DiffDRR/diffdrr/projectors/siddon.py:56\u001b[0m, in \u001b[0;36mSiddon.get_alphas\u001b[0;34m(self, source, target)\u001b[0m\n\u001b[1;32m     52\u001b[0m alphas[\u001b[38;5;241m~\u001b[39mgood_idxs] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnan\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# # Sort the alphas by ray, putting nans at the end of the list\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# # Drop indices where alphas for all rays are nan\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m alphas \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     57\u001b[0m alphas \u001b[38;5;241m=\u001b[39m alphas[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m~\u001b[39malphas\u001b[38;5;241m.\u001b[39misnan()\u001b[38;5;241m.\u001b[39mall(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mall(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)]\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m alphas\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: The operator 'aten::sort.values_stable' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "drr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e71fa102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[250.]], dtype=torch.float64, requires_grad=True)\n",
       "Parameter containing:\n",
       "tensor([[3.1406, 0.0000, 1.5703]], dtype=torch.float64, requires_grad=True)\n",
       "Parameter containing:\n",
       "tensor([[150., 150., 150.]], dtype=torch.float64, requires_grad=True)\n",
       "Parameter containing:\n",
       "tensor([0.7031, 0.7031, 2.5000], dtype=torch.float64)\n",
       "Parameter containing:\n",
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drr.to(\"cpu\").to(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ae61bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
       "               0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
       "               0.0000,      0.0000],\n",
       "         [     0.0000,      0.0000,      0.0000,  ...,      0.0000,\n",
       "               0.0000,      0.0000],\n",
       "         ...,\n",
       "         [     0.0000,      0.0000,      0.0000,  ..., 167733.9253,\n",
       "          167572.3324, 170933.6458],\n",
       "         [     0.0000,      0.0000,      0.0000,  ..., 170623.8087,\n",
       "          169063.3625, 170242.3076],\n",
       "         [     0.0000,      0.0000,      0.0000,  ..., 177162.3036,\n",
       "          174305.1371, 171680.9659]]], dtype=torch.float64,\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2c8e047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.7031, 0.7031, 2.5000], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drr.siddon.spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b93d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11cc050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eb1f5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drr.siddon.volume.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5515146",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = torch.tensor([[0.]]).to(device=\"mps\", dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29b44c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, device(type='cpu'))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.tensor([[1]])\n",
    "test.dtype, test.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c659b829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], device='mps:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.to(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d88cbf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([250.0, 3.14, 0.0, 1.57, 150.0, 150.0, 150.0])\n",
    "_ = drr(*params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8693ec95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a4364ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([250.])\n",
       "Parameter containing:\n",
       "tensor([[3.1400, 0.0000, 1.5700]], requires_grad=True)\n",
       "Parameter containing:\n",
       "tensor([[150., 150., 150.]], requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec28bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4839b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b928ea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "288 ms ± 32.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "_ = drr(*params)\n",
    "print(_.device)\n",
    "\n",
    "%timeit drr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "975ea048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drr.sdr.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ec13372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263 ms ± 24.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "drr.to(\"cpu\")\n",
    "%timeit drr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ea67254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([250.], device='mps:0', dtype=torch.float16)\n",
       "Parameter containing:\n",
       "tensor([[3.1406, 0.0000, 1.5703]], device='mps:0', dtype=torch.float16,\n",
       "       requires_grad=True)\n",
       "Parameter containing:\n",
       "tensor([[150., 150., 150.]], device='mps:0', dtype=torch.float16,\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drr.to(device=\"mps\", dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e1963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeffb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "drr.siddon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af83f15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffdrr import Siddon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9a4cff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "result type Float can't be cast to the desired output type Long",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSiddon\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvolume\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspacing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MedicalVision/DiffDRR/diffdrr/projectors/siddon.py:14\u001b[0m, in \u001b[0;36mSiddon.__init__\u001b[0;34m(self, volume, spacing, eps)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolume \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(volume)\u001b[38;5;241m.\u001b[39mflip([\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolume\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: result type Float can't be cast to the desired output type Long"
     ]
    }
   ],
   "source": [
    "Siddon(volume, spacing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a621baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(volume.shape).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74de57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03778ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(volume.shape)\n",
    "t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bf0ed19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([513, 513, 134])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bf8acce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe5628a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DiffDRR]",
   "language": "python",
   "name": "conda-env-DiffDRR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
